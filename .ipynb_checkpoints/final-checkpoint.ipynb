{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "\n",
    "import sklearn.naive_bayes as NB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from preprocessing.Preprocessing import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14392\n",
      "3739\n"
     ]
    }
   ],
   "source": [
    "ds = pd.read_csv('D:\\\\Dataset\\\\EE655000MachineLearning\\\\Aidea\\\\train.csv')\n",
    "test_ds = pd.read_csv('D:\\\\Dataset\\\\EE655000MachineLearning\\\\Aidea\\\\test.csv')\n",
    "ds_season = pd.read_csv('D:\\\\Dataset\\\\EE655000MachineLearning\\\\Aidea\\\\season.csv')\n",
    "print(len(ds))\n",
    "print(len(test_ds))\n",
    "#ds.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(ds.columns)\n",
    "columns.remove('最高學歷')\n",
    "columns.remove('畢業學校類別')\n",
    "ds = ds.loc[:,columns]\n",
    "test_ds = test_ds.loc[:,columns]\n",
    "test_ds.drop(columns='PerStatus', inplace=True)\n",
    "#test_ds.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14319\n"
     ]
    }
   ],
   "source": [
    "ds.dropna(inplace=True)\n",
    "test_ds_valid = test_ds.dropna().copy()\n",
    "test_ds_invalid = test_ds[test_ds.isna().any(axis=1)].copy()\n",
    "print(len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yyyy</th>\n",
       "      <th>PerNo</th>\n",
       "      <th>sex</th>\n",
       "      <th>工作分類</th>\n",
       "      <th>職等</th>\n",
       "      <th>廠區代碼</th>\n",
       "      <th>管理層級</th>\n",
       "      <th>工作資歷1</th>\n",
       "      <th>工作資歷2</th>\n",
       "      <th>工作資歷3</th>\n",
       "      <th>...</th>\n",
       "      <th>年齡層級</th>\n",
       "      <th>婚姻狀況</th>\n",
       "      <th>年資層級A</th>\n",
       "      <th>年資層級B</th>\n",
       "      <th>年資層級C</th>\n",
       "      <th>任職前工作平均年數</th>\n",
       "      <th>畢業科系類別</th>\n",
       "      <th>眷屬量</th>\n",
       "      <th>通勤成本</th>\n",
       "      <th>歸屬部門</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2018</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2018</td>\n",
       "      <td>276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>2018</td>\n",
       "      <td>535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>2018</td>\n",
       "      <td>785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>2018</td>\n",
       "      <td>1075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>2018</td>\n",
       "      <td>2317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>2018</td>\n",
       "      <td>3109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>2018</td>\n",
       "      <td>4324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>2018</td>\n",
       "      <td>4537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051</th>\n",
       "      <td>2018</td>\n",
       "      <td>4831</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>2018</td>\n",
       "      <td>5037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2563</th>\n",
       "      <td>2018</td>\n",
       "      <td>6037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>2018</td>\n",
       "      <td>6070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2807</th>\n",
       "      <td>2018</td>\n",
       "      <td>6556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065</th>\n",
       "      <td>2018</td>\n",
       "      <td>7191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>2018</td>\n",
       "      <td>7514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3389</th>\n",
       "      <td>2018</td>\n",
       "      <td>7973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3454</th>\n",
       "      <td>2018</td>\n",
       "      <td>8117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      yyyy  PerNo  sex  工作分類  職等  廠區代碼  管理層級  工作資歷1  工作資歷2  工作資歷3  ...  年齡層級  \\\n",
       "34    2018     87  NaN   NaN NaN   NaN   NaN    NaN    NaN    NaN  ...   NaN   \n",
       "101   2018    276  NaN   NaN NaN   NaN   NaN    NaN    NaN    NaN  ...   NaN   \n",
       "206   2018    535  NaN   NaN NaN   NaN   NaN    NaN    NaN    NaN  ...   NaN   \n",
       "311   2018    785  NaN   NaN NaN   NaN   NaN    NaN    NaN    NaN  ...   NaN   \n",
       "447   2018   1075  NaN   NaN NaN   NaN   NaN    NaN    NaN    NaN  ...   NaN   \n",
       "951   2018   2317  NaN   NaN NaN   NaN   NaN    NaN    NaN    NaN  ...   NaN   \n",
       "1288  2018   3109  NaN   NaN NaN   NaN   NaN    NaN    NaN    NaN  ...   NaN   \n",
       "1830  2018   4324  NaN   NaN NaN   NaN   NaN    NaN    NaN    NaN  ...   NaN   \n",
       "1925  2018   4537  NaN   NaN NaN   NaN   NaN    NaN    NaN    NaN  ...   NaN   \n",
       "2051  2018   4831  NaN   NaN NaN   NaN   NaN    NaN    NaN    NaN  ...   NaN   \n",
       "2143  2018   5037  NaN   NaN NaN   NaN   NaN    NaN    NaN    NaN  ...   NaN   \n",
       "2563  2018   6037  NaN   NaN NaN   NaN   NaN    NaN    NaN    NaN  ...   NaN   \n",
       "2577  2018   6070  NaN   NaN NaN   NaN   NaN    NaN    NaN    NaN  ...   NaN   \n",
       "2807  2018   6556  NaN   NaN NaN   NaN   NaN    NaN    NaN    NaN  ...   NaN   \n",
       "3065  2018   7191  NaN   NaN NaN   NaN   NaN    NaN    NaN    NaN  ...   NaN   \n",
       "3195  2018   7514  NaN   NaN NaN   NaN   NaN    NaN    NaN    NaN  ...   NaN   \n",
       "3389  2018   7973  NaN   NaN NaN   NaN   NaN    NaN    NaN    NaN  ...   NaN   \n",
       "3454  2018   8117  NaN   NaN NaN   NaN   NaN    NaN    NaN    NaN  ...   NaN   \n",
       "\n",
       "      婚姻狀況  年資層級A  年資層級B  年資層級C  任職前工作平均年數  畢業科系類別  眷屬量  通勤成本  歸屬部門  \n",
       "34     NaN    NaN    NaN    NaN        NaN     NaN  NaN   NaN   NaN  \n",
       "101    NaN    NaN    NaN    NaN        NaN     NaN  NaN   NaN   NaN  \n",
       "206    NaN    NaN    NaN    NaN        NaN     NaN  NaN   NaN   NaN  \n",
       "311    NaN    NaN    NaN    NaN        NaN     NaN  NaN   NaN   NaN  \n",
       "447    NaN    NaN    NaN    NaN        NaN     NaN  NaN   NaN   NaN  \n",
       "951    NaN    NaN    NaN    NaN        NaN     NaN  NaN   NaN   NaN  \n",
       "1288   NaN    NaN    NaN    NaN        NaN     NaN  NaN   NaN   NaN  \n",
       "1830   NaN    NaN    NaN    NaN        NaN     NaN  NaN   NaN   NaN  \n",
       "1925   NaN    NaN    NaN    NaN        NaN     NaN  NaN   NaN   NaN  \n",
       "2051   NaN    NaN    NaN    NaN        NaN     NaN  NaN   NaN   NaN  \n",
       "2143   NaN    NaN    NaN    NaN        NaN     NaN  NaN   NaN   NaN  \n",
       "2563   NaN    NaN    NaN    NaN        NaN     NaN  NaN   NaN   NaN  \n",
       "2577   NaN    NaN    NaN    NaN        NaN     NaN  NaN   NaN   NaN  \n",
       "2807   NaN    NaN    NaN    NaN        NaN     NaN  NaN   NaN   NaN  \n",
       "3065   NaN    NaN    NaN    NaN        NaN     NaN  NaN   NaN   NaN  \n",
       "3195   NaN    NaN    NaN    NaN        NaN     NaN  NaN   NaN   NaN  \n",
       "3389   NaN    NaN    NaN    NaN        NaN     NaN  NaN   NaN   NaN  \n",
       "3454   NaN    NaN    NaN    NaN        NaN     NaN  NaN   NaN   NaN  \n",
       "\n",
       "[18 rows x 44 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds_invalid # 18 IDs has no valid data in test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13526\n",
       "1      793\n",
       "Name: PerStatus, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.PerStatus.value_counts() # label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = train_test_split(ds, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deprecated\n",
    "num_feats = ['職等',\n",
    "             '管理層級',\n",
    "             '專案時數',\n",
    "             '專案總數',\n",
    "             '特殊專案佔比',\n",
    "             '訓練時數A',\n",
    "             '訓練時數B',\n",
    "             '訓練時數C',\n",
    "             '生產總額',\n",
    "             '榮譽數',\n",
    "             '升遷速度',\n",
    "             '近三月請假數A',\n",
    "             '近一年請假數A',\n",
    "             '近三月請假數B',\n",
    "             '近一年請假數B',\n",
    "             '出差數A',\n",
    "             '出差數B',\n",
    "             '出差集中度', \n",
    "             '年度績效等級A',\n",
    "             '年度績效等級B',\n",
    "             '年度績效等級C',\n",
    "             '年齡層級',\n",
    "             '年資層級A',\n",
    "             '年資層級B',\n",
    "             '年資層級C',\n",
    "             '任職前工作平均年數',\n",
    "             '眷屬量',\n",
    "             '通勤成本',\n",
    "             ]\n",
    "cat_feats = ['sex',\n",
    "             '工作分類',\n",
    "             '廠區代碼',\n",
    "             '工作資歷1',\n",
    "             '工作資歷2',\n",
    "             '工作資歷3',\n",
    "             '工作資歷4',\n",
    "             '工作資歷5',\n",
    "             '當前專案角色',\n",
    "             '工作地點',\n",
    "             '是否升遷',\n",
    "             '婚姻狀況',\n",
    "             '畢業科系類別',\n",
    "             '歸屬部門',\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178\n",
      "178\n"
     ]
    }
   ],
   "source": [
    "X_train_num = train_ds.loc[:,num_feats]\n",
    "X_train_cat = train_ds.loc[:,cat_feats]\n",
    "X_train_all_ = train_ds.iloc[:,3:]\n",
    "y_train = train_ds.PerStatus\n",
    "\n",
    "X_val_num = val_ds.loc[:,num_feats]\n",
    "X_val_cat = val_ds.loc[:,cat_feats]\n",
    "X_val_all_ = val_ds.iloc[:,3:]\n",
    "y_val = val_ds.PerStatus\n",
    "\n",
    "X_test_num = test_ds_valid.loc[:,num_feats]\n",
    "X_test_cat = test_ds_valid.loc[:,cat_feats]\n",
    "X_test_all_ = test_ds_valid.iloc[:,2:]\n",
    "\n",
    "X_num = ds.loc[:,num_feats]\n",
    "X_cat = ds.loc[:,cat_feats]\n",
    "X_all_ = ds.iloc[:,3:]\n",
    "y = ds.PerStatus\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train_num)\n",
    "X_train_num.loc[:,num_feats] = sc.transform(X_train_num)\n",
    "X_val_num.loc[:,num_feats] = sc.transform(X_val_num)\n",
    "X_train_all = pd.concat([X_train_cat, X_train_num], axis=1)\n",
    "X_val_all = pd.concat([X_val_cat, X_val_num], axis=1)\n",
    "\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_num)\n",
    "X_num.loc[:,num_feats] = sc.transform(X_num)\n",
    "X_test_num.loc[:,num_feats] = sc.transform(X_test_num)\n",
    "X_all = pd.concat([X_cat, X_num], axis=1)\n",
    "X_test_all = pd.concat([X_test_cat, X_test_num], axis=1)\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "ohe.fit(X_train_cat)\n",
    "X_train_ohe = ohe.transform(X_train_cat).toarray()\n",
    "ohe_len = X_train_ohe.shape[1]\n",
    "print(ohe_len)\n",
    "X_val_ohe = ohe.transform(X_val_cat).toarray()\n",
    "X_train_num_ohe = np.hstack((X_train_ohe, X_train_num.values))\n",
    "X_val_num_ohe = np.hstack((X_val_ohe, X_val_num.values))\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "ohe.fit(X_cat)\n",
    "X_ohe = ohe.transform(X_cat).toarray()\n",
    "ohe_len = X_ohe.shape[1]\n",
    "print(ohe_len)\n",
    "X_test_ohe = ohe.transform(X_test_cat).toarray()\n",
    "X_num_ohe = np.hstack((X_ohe, X_num.values))\n",
    "X_test_num_ohe = np.hstack((X_test_ohe, X_test_num.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_beta_score(y_true, y_pred, beta=1.5):\n",
    "    \"\"\"F beta score with beta=1.5\"\"\"\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    f_beta = (1+beta**2)*(prec*rec)/(beta**2*prec + rec)\n",
    "    return f_beta\n",
    "\n",
    "def fit_and_predict(model, X_train, y_trian, X_val, y_val):\n",
    "    \"\"\"Fast apply of an classifier on training and validation set\"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_train)\n",
    "    print(f'Trainning Beta F1 score: {F_beta_score(y_train, y_pred):.4f}')\n",
    "    y_pred = model.predict(X_val)\n",
    "    print(f'Validation Beta F1 score: {F_beta_score(y_val, y_pred):.4f}')\n",
    "    return y_pred\n",
    "\n",
    "def make_submission(model, X_train, y_train, X_test, test_ds_valid, test_ds_invalid, test_ds):\n",
    "    \"\"\"output valid submission model\"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)[:,np.newaxis]\n",
    "    output_no = test_ds_valid.loc[:,'PerNo'].values[:,np.newaxis]\n",
    "    output_valid = np.hstack((output_no, y_pred))\n",
    "    #print(output_valid.shape)\n",
    "    \n",
    "    # for 18 IDs with no valid data, apply random predict\n",
    "    per_invalid = test_ds_invalid.PerNo.values[:,np.newaxis]\n",
    "    y_pred_invalid = np.random.rand(len(per_invalid))\n",
    "    y_pred_invalid = np.array([1 if y_<0.05 else 0 for y_ in y_pred_invalid])[:,np.newaxis]\n",
    "    output_invalid = np.hstack((per_invalid, y_pred_invalid))\n",
    "    #print(output_invalid.shape)\n",
    "    \n",
    "    output = np.vstack((output_valid,output_invalid))\n",
    "    output_ds = pd.DataFrame(output, columns=['PerNo', 'PerStatus'])\n",
    "    \n",
    "    output_ds = output_ds.set_index('PerNo')\n",
    "    output_ds = output_ds.reindex(index=test_ds['PerNo'])\n",
    "    output_ds = output_ds.reset_index()\n",
    "    return output_ds\n",
    "\n",
    "def voter(clf_results, clf_weights):\n",
    "    \"\"\"\n",
    "    clf_result - shape = n X m\n",
    "                 n: number of samples, m: number of classifiers\n",
    "                 \n",
    "    clf_weights - weight for each classifier\n",
    "    \"\"\"\n",
    "    assert clf_results.shape[1]-1==len(clf_weights), \"# of weights must be equal to # of classifiers\"\n",
    "    pred1_score = clf_results.copy()\n",
    "    pred0_score = clf_results.copy()\n",
    "    pred0_score.iloc[:,1:] = pred0_score.iloc[:,1:].apply(lambda x: 1-x)\n",
    "    for i in range(len(clf_weights)):\n",
    "        w = clf_weights[i]\n",
    "        pred1_score.iloc[:,i+1] = pred1_score.iloc[:,i+1].apply(lambda x: w*x)\n",
    "        pred0_score.iloc[:,i+1] = pred0_score.iloc[:,i+1].apply(lambda x: w*x)\n",
    "    pred1_score_value = pred1_score.iloc[:,1:].sum(axis=1)\n",
    "    pred0_score_value = pred0_score.iloc[:,1:].sum(axis=1)\n",
    "    vote_result = np.array([1 if p1>p0 else 0 for p1, p0 in zip(pred1_score_value, pred0_score_value)])\n",
    "    output = pd.DataFrame(clf_results.PerNo)\n",
    "    output['PerStatus'] = vote_result\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11455, 206)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_num_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class seqDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        #print(data.shape)\n",
    "        self.n_samples = data.shape[0]\n",
    "        self.seq_data = torch.from_numpy(data)\n",
    "    def __getitem__(self, index):\n",
    "        return self.seq_data[index]\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "class MLP:\n",
    "    def __init__(self, batch_size=32, epochs=10, lr=1e-3):\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.model = nn.Sequential(nn.Linear(206, 16),\n",
    "                                   #nn.Tanh(),\n",
    "                                   #nn.Linear(128, 16),\n",
    "                                   nn.Tanh(),\n",
    "                                   nn.Linear(16,2))\n",
    "        self.model.cuda()\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        data = np.hstack((X, y.values.reshape(-1,1)))\n",
    "        dataset = seqDataset(data)\n",
    "        train_loader = DataLoader(dataset, batch_size=self.batch_size)\n",
    "        \n",
    "        class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y.values)\n",
    "        class_weights=torch.tensor(class_weights,dtype=torch.float).cuda()\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.model.train()\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            total_loss = 0\n",
    "            step = 0\n",
    "            for i, data in enumerate(train_loader):\n",
    "                #data = torch.tensor(data)\n",
    "                feat = data[:,:-1].float().cuda()\n",
    "                label = data[:,-1].to(torch.int64).cuda()\n",
    "                output = self.model(feat)\n",
    "                self.output = output\n",
    "                self.label = label\n",
    "                loss = criterion(output, label)\n",
    "                optimizer.zero_grad()\n",
    "                total_loss += loss.item()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                step += 1\n",
    "            if epoch % 5 == 0:\n",
    "                print(f'Epoch [{epoch}/{self.epochs}]. Average loss: {total_loss/step:.6f}\\n')\n",
    "            \n",
    "    def predict(self, X):\n",
    "        X_tensor = torch.Tensor(X).float().cuda()\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_prob = self.model(X_tensor)\n",
    "        y_prob = y_prob.cpu().numpy()\n",
    "        y_pred = np.argmax(y_prob, axis=1)\n",
    "        \n",
    "        return y_pred.flatten()\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/20]. Average loss: 0.662619\n",
      "\n",
      "Epoch [5/20]. Average loss: 0.605897\n",
      "\n",
      "Epoch [10/20]. Average loss: 0.590257\n",
      "\n",
      "Epoch [15/20]. Average loss: 0.580030\n",
      "\n",
      "Trainning Beta F1 score: 0.2936\n",
      "Validation Beta F1 score: 0.2676\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 20\n",
    "lr = 1e-4\n",
    "\n",
    "mlp = MLP(batch_size=batch_size, epochs=epochs, lr=lr)\n",
    "y_pred_mlp = fit_and_predict(mlp, X_train_num_ohe, y_train, X_val_num_ohe, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/20]. Average loss: 0.691047\n",
      "\n",
      "Epoch [5/20]. Average loss: 0.615143\n",
      "\n",
      "Epoch [10/20]. Average loss: 0.592886\n",
      "\n",
      "Epoch [15/20]. Average loss: 0.579577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 20\n",
    "lr = 1e-4\n",
    "\n",
    "mlp = MLP(batch_size=batch_size, epochs=epochs, lr=lr)\n",
    "submission_mlp = make_submission(mlp, X_num_ohe, y, X_test_num_ohe, test_ds_valid, test_ds_invalid, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning Beta F1 score: 0.1891\n",
      "Validation Beta F1 score: 0.2129\n"
     ]
    }
   ],
   "source": [
    "mnb = NB.MultinomialNB()\n",
    "y_pred_mnb = fit_and_predict(mnb, X_train_all_, y_train, X_val_all_, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = NB.MultinomialNB()\n",
    "submission_mnb = make_submission(mnb, X_all_, y, X_test_all_, test_ds_valid, test_ds_invalid, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning Beta F1 score: 0.2388\n",
      "Validation Beta F1 score: 0.2392\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(class_weight='balanced', max_iter=500)\n",
    "y_pred_lr = fit_and_predict(lr, X_train_all, y_train, X_val_all, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(class_weight='balanced', max_iter=500)\n",
    "submission_lr = make_submission(lr, X_all, y, X_test_all, test_ds_valid, test_ds_invalid, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning Beta F1 score: 0.2952\n",
      "Validation Beta F1 score: 0.2431\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=50, max_depth=5, class_weight='balanced', random_state=40)\n",
    "y_pred_rf = fit_and_predict(rf, X_train_num_ohe, y_train, X_val_num_ohe, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=50, max_depth=5, class_weight='balanced')\n",
    "submission_rf = make_submission(rf, X_num_ohe, y, X_test_num_ohe, test_ds_valid, test_ds_invalid, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainning Beta F1 score: 0.3065\n",
      "Validation Beta F1 score: 0.2655\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=1e-1, class_weight='balanced')\n",
    "y_pred_svc = fit_and_predict(svc, X_train_num_ohe, y_train, X_val_num_ohe, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=1e-1, class_weight='balanced')\n",
    "submission_svc = make_submission(svc, X_num_ohe, y, X_test_num_ohe, test_ds_valid, test_ds_invalid, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_svc.to_csv('./submission/submission_svc.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\.conda\\envs\\tiles\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:50:23] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Trainning Beta F1 score: 0.4972\n",
      "Validation Beta F1 score: 0.2439\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(n_estimators=100, max_depth=5, scale_pos_weight=99)\n",
    "y_pred_xgb = fit_and_predict(xgb, X_train_all, y_train, X_val_all, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:50:23] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(n_estimators=100, max_depth=5, scale_pos_weight=99)\n",
    "submission_xgb = make_submission(xgb, X_all, y, X_test_all, test_ds_valid, test_ds_invalid, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_results = pd.DataFrame(val_ds.PerNo)\n",
    "clf_results['mnb'] = y_pred_mnb\n",
    "#clf_results['lr'] = y_pred_lr\n",
    "clf_results['rf'] = y_pred_rf\n",
    "clf_results['svc'] = y_pred_svc\n",
    "clf_results['xgb'] = y_pred_xgb\n",
    "#clf_results['mlp'] = y_pred_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2785176606832657"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_result = voter(clf_results, [1,1,1,1])\n",
    "y_pred = vote_result.PerStatus.values\n",
    "F_beta_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_mlp2 = pd.read_csv('./submission/submission_mlp2.csv')\n",
    "submission_mlp3 = pd.read_csv('./submission/submission_mlp3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PerNo</th>\n",
       "      <th>mnb</th>\n",
       "      <th>rf</th>\n",
       "      <th>svc</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3734</th>\n",
       "      <td>8761</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3735</th>\n",
       "      <td>8765</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3736</th>\n",
       "      <td>8767</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3737</th>\n",
       "      <td>8774</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>8775</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3739 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PerNo  mnb  rf  svc  xgb\n",
       "0         1    0   0    0    0\n",
       "1         3    0   0    0    0\n",
       "2         7    1   1    1    1\n",
       "3        15    0   0    0    0\n",
       "4        16    1   0    1    0\n",
       "...     ...  ...  ..  ...  ...\n",
       "3734   8761    0   1    1    1\n",
       "3735   8765    0   0    0    0\n",
       "3736   8767    0   1    1    0\n",
       "3737   8774    0   0    0    0\n",
       "3738   8775    0   0    1    0\n",
       "\n",
       "[3739 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(submission_mnb.PerNo)\n",
    "submission['mnb'] = submission_mnb['PerStatus']\n",
    "#submission['lr'] = submission_lr['PerStatus']\n",
    "submission['rf'] = submission_rf['PerStatus']\n",
    "submission['svc'] = submission_svc['PerStatus']\n",
    "submission['xgb'] = submission_xgb['PerStatus']\n",
    "#submission['mlp'] = submission_mlp['PerStatus']\n",
    "#submission['mlp2'] = submission_mlp2['PerStatus']\n",
    "#submission['mlp3'] = submission_mlp3['PerStatus']\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PerNo</th>\n",
       "      <th>PerStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3734</th>\n",
       "      <td>8761</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3735</th>\n",
       "      <td>8765</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3736</th>\n",
       "      <td>8767</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3737</th>\n",
       "      <td>8774</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>8775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3739 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PerNo  PerStatus\n",
       "0         1          0\n",
       "1         3          0\n",
       "2         7          1\n",
       "3        15          0\n",
       "4        16          0\n",
       "...     ...        ...\n",
       "3734   8761          1\n",
       "3735   8765          0\n",
       "3736   8767          0\n",
       "3737   8774          0\n",
       "3738   8775          0\n",
       "\n",
       "[3739 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = voter(submission, [1,1,1,1])\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./submission/voter[1 1 1 1]_v3_mnb_rf_svc_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6650721582617155"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_beta_score(submission_svc['PerStatus'], submission_mlp['PerStatus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
